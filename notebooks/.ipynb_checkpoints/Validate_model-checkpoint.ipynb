{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "from keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Dropbox\\Projektit\\Sähköbussit\\TripPredictor_3\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive E is Storage\n",
      " Volume Serial Number is EC63-9DAD\n",
      "\n",
      " Directory of E:\\Dropbox\\Projektit\\S„hk”bussit\\TripPredictor_3\n",
      "\n",
      "02.10.2018  09:49    <DIR>          .\n",
      "02.10.2018  09:49    <DIR>          ..\n",
      "02.10.2018  10:36    <DIR>          .git\n",
      "19.09.2018  16:46                80 .gitignore\n",
      "02.10.2018  10:36    <DIR>          .idea\n",
      "19.09.2018  19:09    <DIR>          .ipynb_checkpoints\n",
      "01.10.2018  22:58    <DIR>          __pycache__\n",
      "01.10.2018  23:42                 0 01-10-2018__23_42_00.log\n",
      "02.10.2018  00:13                 0 02-10-2018__00_13_03.log\n",
      "02.10.2018  00:14                 0 02-10-2018__00_14_30.log\n",
      "02.10.2018  00:16                 0 02-10-2018__00_16_03.log\n",
      "02.10.2018  00:17                 0 02-10-2018__00_17_34.log\n",
      "02.10.2018  00:27                 0 02-10-2018__00_27_29.log\n",
      "02.10.2018  10:34        13ÿ591ÿ544 02-10-2018__09_43_02.h5\n",
      "02.10.2018  10:34               371 02-10-2018__09_43_02.log\n",
      "01.10.2018  23:03    <DIR>          data\n",
      "14.09.2018  13:35               270 dump.m\n",
      "01.10.2018  23:00    <DIR>          models\n",
      "02.10.2018  10:37    <DIR>          notebooks\n",
      "01.10.2018  22:58             6ÿ247 prepare_data.py\n",
      "01.10.2018  22:34               271 preprocess.bat\n",
      "28.09.2018  16:11            10ÿ149 preprocess_tests.py\n",
      "22.09.2018  17:32             9ÿ068 preprocess_utils.py\n",
      "19.09.2018  16:36                85 README.md\n",
      "01.10.2018  23:07                53 train.bat\n",
      "02.10.2018  00:27             5ÿ918 train.py\n",
      "14.09.2018  14:30                 0 trips_bulk.m\n",
      "              18 File(s)     13ÿ624ÿ056 bytes\n",
      "               9 Dir(s)  646ÿ848ÿ962ÿ560 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log = pd.read_csv('02-10-2018__09_43_02.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.320341</td>\n",
       "      <td>0.229842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.218281</td>\n",
       "      <td>0.196286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.195839</td>\n",
       "      <td>0.293564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.188718</td>\n",
       "      <td>0.166474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.168894</td>\n",
       "      <td>0.179509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.148482</td>\n",
       "      <td>0.122336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.122299</td>\n",
       "      <td>0.115397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.115880</td>\n",
       "      <td>0.105264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch      loss  val_loss\n",
       "0      0  0.320341  0.229842\n",
       "1      1  0.218281  0.196286\n",
       "2      2  0.195839  0.293564\n",
       "3      3  0.188718  0.166474\n",
       "4      4  0.168894  0.179509\n",
       "5      5  0.148482  0.122336\n",
       "6      6  0.122299  0.115397\n",
       "7      7  0.115880  0.105264"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('02-10-2018__09_43_02.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = pickle.load(open('./data/trips_fullscale_dataset.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5076"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceBatchGenerator(Sequence):\n",
    "    \"\"\"\n",
    "        A generator class to produce a single batch of sequences\n",
    "        for LSTM training\n",
    "\n",
    "        Arguments:\n",
    "            x_set: The whole training set, python list of length m_examples.\n",
    "            A single example can be accessed in the manner x_set[example_idx]\n",
    "            and is a numpy array of shape (1, timesteps, n_features). Timesteps\n",
    "            can vary between examples.\n",
    "\n",
    "            y_set: The labels corresponding to elements in x_set\n",
    "\n",
    "            batch_size: The batch size to be used in training\n",
    "\n",
    "        Outputs:\n",
    "            batch_x_tensor: Numpy array of shape (batch_size, max_timesteps_batch,\n",
    "            n_input_features)\n",
    "            batch_y_tensor: Numpy array of shape (batch_size, max_timesteps_batch,\n",
    "            n_output_features)\n",
    "\n",
    "\n",
    "        #https://keras.io/utils/#sequence\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x_set, y_set, batch_size=128):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Make sure n_features is same for all examples\n",
    "        unique_input_dims = len(set([example.shape[2] for example in x_set]))\n",
    "        unique_output_dims = len(set([example.shape[2] for example in y_set]))\n",
    "        if not unique_input_dims == unique_output_dims == 1:\n",
    "            raise Exception(\"n_features needs to be same for all examples\")\n",
    "\n",
    "        self.input_dim = x_set[0].shape[2]\n",
    "        self.output_dim = y_set[0].shape[2]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size].copy()\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size].copy()\n",
    "\n",
    "        # get all the stuff required for reshaping\n",
    "        max_timesteps_batch = max([seq.shape[1] for seq in batch_x])\n",
    "\n",
    "        # initialize return variables as 3D tensors\n",
    "        batch_x_tensor = np.zeros((len(batch_x), max_timesteps_batch, self.input_dim))\n",
    "        batch_y_tensor = np.zeros((len(batch_y), max_timesteps_batch, self.output_dim))\n",
    "\n",
    "        # Zero pad all samples within batch to max length\n",
    "        for i in range(len(batch_x)):\n",
    "            padding_dims = ((0, 0), (0, max_timesteps_batch - batch_x[i].shape[1]), (0, 0))\n",
    "            batch_x[i] = np.pad(batch_x[i], padding_dims, 'constant', constant_values=(None, 0))\n",
    "            batch_y[i] = np.pad(batch_y[i], padding_dims, 'constant', constant_values=(None, 0))\n",
    "\n",
    "            # Reshape to meet Keras expectation\n",
    "            batch_x[i][0] = np.reshape(batch_x[i].transpose(), (1, max_timesteps_batch, self.input_dim))\n",
    "            batch_y[i][0] = np.reshape(batch_y[i].transpose(), (1, max_timesteps_batch, self.output_dim))\n",
    "\n",
    "            # Append x, y to returnable tensor\n",
    "            batch_x_tensor[i, :, :] = batch_x[i]\n",
    "            batch_y_tensor[i, :, :] = batch_y[i]\n",
    "\n",
    "        return batch_x_tensor, batch_y_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_test_gen = SequenceBatchGenerator(X_test, y_test, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(len(batch_test_gen)):\n",
    "    batch_x_tensor = batch_test_gen.__getitem__(i)\n",
    "    preds.append(model.predict_on_batch(batch_x_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5076"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 206, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100, 1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 199, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 206, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5076"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(preds, open('preds_dump.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive E is Storage\n",
      " Volume Serial Number is EC63-9DAD\n",
      "\n",
      " Directory of E:\\Dropbox\\Projektit\\S„hk”bussit\\TripPredictor_3\n",
      "\n",
      "02.10.2018  11:36    <DIR>          .\n",
      "02.10.2018  11:36    <DIR>          ..\n",
      "02.10.2018  10:45    <DIR>          .git\n",
      "19.09.2018  16:46                80 .gitignore\n",
      "02.10.2018  10:45    <DIR>          .idea\n",
      "19.09.2018  19:09    <DIR>          .ipynb_checkpoints\n",
      "01.10.2018  22:58    <DIR>          __pycache__\n",
      "01.10.2018  23:42                 0 01-10-2018__23_42_00.log\n",
      "02.10.2018  00:13                 0 02-10-2018__00_13_03.log\n",
      "02.10.2018  00:14                 0 02-10-2018__00_14_30.log\n",
      "02.10.2018  00:16                 0 02-10-2018__00_16_03.log\n",
      "02.10.2018  00:17                 0 02-10-2018__00_17_34.log\n",
      "02.10.2018  00:27                 0 02-10-2018__00_27_29.log\n",
      "02.10.2018  10:34        13ÿ591ÿ544 02-10-2018__09_43_02.h5\n",
      "02.10.2018  10:34               371 02-10-2018__09_43_02.log\n",
      "01.10.2018  23:03    <DIR>          data\n",
      "14.09.2018  13:35               270 dump.m\n",
      "01.10.2018  23:00    <DIR>          models\n",
      "02.10.2018  11:35    <DIR>          notebooks\n",
      "02.10.2018  11:36         3ÿ482ÿ510 preds_dump.pickle\n",
      "01.10.2018  22:58             6ÿ247 prepare_data.py\n",
      "01.10.2018  22:34               271 preprocess.bat\n",
      "28.09.2018  16:11            10ÿ149 preprocess_tests.py\n",
      "22.09.2018  17:32             9ÿ068 preprocess_utils.py\n",
      "19.09.2018  16:36                85 README.md\n",
      "01.10.2018  23:07                53 train.bat\n",
      "02.10.2018  00:27             5ÿ918 train.py\n",
      "14.09.2018  14:30                 0 trips_bulk.m\n",
      "              19 File(s)     17ÿ106ÿ566 bytes\n",
      "               9 Dir(s)  646ÿ845ÿ464ÿ576 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes = []\n",
    "for pred, ground_truth in zip(preds, y_test):\n",
    "    error = np.mean(np.abs(pred - ground_truth))\n",
    "    maes.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5076"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(maes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = np.mean(maes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20317749217645606"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgen = SequenceBatchGenerator(X_test, y_test, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10214438296449381"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(tgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10214438296449381"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(tgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgen = SequenceBatchGenerator(X_test, y_test, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10526444092451634"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(tgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10526444092451634"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(tgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgen = SequenceBatchGenerator(X_test, y_test, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.203177491900892"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(tgen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue : Using a larger batch size results in overly optimistic MAE in evaluation, because of the additional zero padding in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
